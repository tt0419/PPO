curriculum:
  enabled: false
  stages: []
data:
  area_restriction:
    action_dim: 192
    area_name: 東京23区
    districts:
    - 千代田区
    - 中央区
    - 港区
    - 新宿区
    - 文京区
    - 台東区
    - 墨田区
    - 江東区
    - 品川区
    - 目黒区
    - 大田区
    - 世田谷区
    - 渋谷区
    - 中野区
    - 杉並区
    - 豊島区
    - 北区
    - 荒川区
    - 板橋区
    - 練馬区
    - 足立区
    - 葛飾区
    - 江戸川区
    enabled: true
    num_ambulances_in_area: 192
    section_code: null
    state_dim: 999
  data_paths:
    grid_mapping: data/tokyo/processed/grid_mapping_res9.json
    travel_time_matrix: data/tokyo/calibration2/linear_calibrated_response.npy
  episode_duration_hours: 24
  eval_periods:
  - end_date: '20230211'
    start_date: '20230205'
  exclude_daytime_ambulances: true
  max_steps_per_episode: 5000
  train_periods:
  - end_date: '20230204'
    start_date: '20230122'
data_paths:
  grid_mapping: data/tokyo/processed/grid_mapping_res9.json
  travel_time_matrix: data/tokyo/calibration2/linear_calibrated_response.npy
evaluation:
  compare_baselines:
  - closest
  - severity_based
  interval: 50
  metrics:
  - severe_6min_rate
  - severe_mean_rt
  - mild_13min_rate
  - mild_mean_rt
  - overall_13min_rate
  - overall_mean_rt
  - coverage_score
  - closest_agreement_rate
  - dispatch_distribution
  n_eval_episodes: 3
experiment:
  description: 検証用 - PPOが直近隊以外を選択できるか確認
  device: cuda
  name: verification_exploration_v1
  seed: 2025
hybrid_mode:
  coverage_evaluation:
    high_risk_weight: 0.7
    min_acceptable: 0.5
    normal_weight: 0.3
  enabled: true
  penalties:
    over_warning: -10.0
    per_minute_over: -0.5
  reward_weights:
    coverage: 0.9
    response_time: 0.05
    workload_balance: 0.05
  severity_classification:
    mild_conditions:
    - 軽症
    - 中等症
    severe_conditions:
    - 重症
    - 重篤
    - 死亡
  time_thresholds:
    good: 13
    warning: 20
inherits: ./config.yaml
network:
  actor:
    activation: relu
    dropout: 0.05
    hidden_layers:
    - 256
    - 128
    initialization: xavier_uniform
  critic:
    activation: relu
    dropout: 0.05
    hidden_layers:
    - 256
    - 128
    init_scale: 0.001
ppo:
  batch_size: 512
  clip_epsilon: 0.2
  entropy_coef: 0.05
  gae_lambda: 0.95
  gamma: 0.99
  learning_rate:
    actor: 0.001
    critic: 0.003
    scheduler: constant
  max_grad_norm: 1.0
  n_episodes: 1500
  n_epochs: 8
reward:
  core:
    continuous_params:
      critical:
        max_bonus: 100.0
        penalty_scale: 10.0
        target: 6
        weight: 1.0
      mild:
        max_bonus: 5.0
        penalty_scale: 0.1
        target: 13
        weight: 0.1
      moderate:
        max_bonus: 5.0
        penalty_scale: 0.1
        target: 13
        weight: 0.1
    coverage_impact_weight: 0.9
    discrete_params:
      penalties:
        over_13min: -5.0
        over_6min: -30.0
        per_minute_over: -0.3
      weights:
        coverage_preservation: 5.0
        response_time: 0.3
        severity_bonus: 2.0
    hybrid_params:
      balanced_workload_bonus: 5.0
      coverage_maintenance_bonus: 200.0
      good_coverage_bonus: 300.0
      mild_coverage_bonus: 150.0
      mild_under_13min_bonus: 10.0
      moderate_under_13min_bonus: 20.0
      non_closest_bonus: 50.0
      over_13min_penalty: -20.0
      over_20min_penalty: -50.0
      overloaded_penalty: -10.0
      poor_coverage_penalty: -200.0
      time_penalty_per_minute: -0.2
    mode: hybrid
    simple_params:
      critical_under_6min_bonus: 50.0
      imitation_bonus: 0.0
      mild_under_13min_bonus: 3.0
      moderate_under_13min_bonus: 5.0
      over_13min_penalty: -3.0
      over_20min_penalty: -10.0
      time_penalty_per_minute: -0.1
  coverage_params:
    drop_penalty_threshold: 0.03
    drop_penalty_weight: -100.0
    evaluation_interval: 50
    time_threshold_seconds: 360
  episode:
    achievement_bonuses:
      coverage_maintained: 100.0
      critical_6min_rate: 50.0
      mild_13min_rate: 10.0
      mild_20min_rate: 5.0
      rate_13min: 5.0
      rate_6min: 20.0
      severe_6min_rate: 30.0
    base_penalty_per_minute: -0.1
    failure_penalty_per_incident: -1.0
  system:
    dispatch_failure: -1.0
    no_available_ambulance: 0.0
    unhandled_call_penalty: -1.0
reward_mode:
  mode: hybrid
severity:
  categories:
    critical:
      conditions:
      - 重症
      - 重篤
      - 死亡
      reward_weight: 1.0
      time_limit_seconds: 360
    mild:
      conditions:
      - 軽症
      reward_weight: 0.1
      time_limit_seconds: 780
    moderate:
      conditions:
      - 中等症
      reward_weight: 0.1
      time_limit_seconds: 780
  thresholds:
    golden_time: 360
    standard_time: 780
state_encoding:
  coverage_feature_dim: 10
  include_coverage_features: true
  mode: compact
  normalization:
    max_station_distance_km: 10
    max_travel_time_minutes: 30
  top_k: 20
teacher:
  apply_to:
  - 軽症
  - 中等症
  decay_episodes: 500
  enabled: false
  final_prob: 0.0
  initial_prob: 0.0
  strategy: closest
training:
  checkpoint_interval: 100
  early_stopping:
    enabled: false
    metric: coverage_score
    min_delta: 0.01
    mode: max
    patience: 300
  keep_last_n: 5
  logging:
    hybrid_logs:
    - severe_dispatch_count
    - mild_dispatch_count
    - coverage_history
    - closest_agreement_rate
    - action_entropy
    - non_closest_selections
    interval: 5
    tensorboard: true
    wandb: true
    wandb_project: ems_verification_exploration
verification:
  compare_with_closest: true
  enabled: true
  log_action_distribution: true
  log_closest_agreement: true
  log_coverage_reward: true
