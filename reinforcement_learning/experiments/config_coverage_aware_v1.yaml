# config_coverage_aware_v1.yaml
# カバレッジ考慮型報酬設計を使用したPPO学習の設定
# 傷病度考慮運用のロジックを組み込んだ新しい報酬設計
# ================================================================
# 実験設定
# ================================================================
experiment:
  name: hybrid_continuous_ppo_coverage_aware_v1
  seed: 2025
  device: cuda
  description: カバレッジ考慮型報酬設計（傷病度考慮運用のロジックを組み込む）

inherits: ./config.yaml

# ================================================================
# データ設定（東京23区）
# ================================================================
data:
  train_periods:
    - start_date: '20231224'
      end_date: '20231230'
  
  eval_periods:
    - start_date: '20241222'
      end_date: '20241228'
  
  episode_duration_hours: 24
  max_steps_per_episode: 5000
  exclude_daytime_ambulances: true
  
  area_restriction:
    enabled: true
    area_name: 東京23区
    districts:
      - 千代田区
      - 中央区
      - 港区
      - 新宿区
      - 文京区
      - 台東区
      - 墨田区
      - 江東区
      - 品川区
      - 目黒区
      - 大田区
      - 世田谷区
      - 渋谷区
      - 中野区
      - 杉並区
      - 豊島区
      - 北区
      - 荒川区
      - 板橋区
      - 練馬区
      - 足立区
      - 葛飾区
      - 江戸川区
    num_ambulances_in_area: 192
    state_dim: 999
    action_dim: 192
    section_code: null
  
  data_paths:
    grid_mapping: data/tokyo/processed/grid_mapping_res9.json
    travel_time_matrix: data/tokyo/calibration2/linear_calibrated_response.npy

# ================================================================
# 傷病度設定
# ================================================================
severity:
  categories:
    critical:
      conditions: ["重症", "重篤", "死亡"]
      reward_weight: 3.0
      time_limit_seconds: 360  # 6分目標
      
    moderate:
      conditions: ["中等症"]
      reward_weight: 1.5
      time_limit_seconds: 780  # 13分目標
      
    mild:
      conditions: ["軽症"]
      reward_weight: 0.5
      time_limit_seconds: 780  # 13分目標
      
  thresholds:
    golden_time: 360   # 6分（重症系目標）
    standard_time: 780 # 13分（全体目標）

# ================================================================
# PPOハイパーパラメータ
# ================================================================
ppo:
  n_episodes: 3000
  n_epochs: 15
  batch_size: 2048
  
  # PPO基本パラメータ
  clip_epsilon: 0.2
  gamma: 0.99
  gae_lambda: 0.95
  
  # 学習率設定
  learning_rate:
    actor: 0.003
    critic: 0.001
    scheduler: cosine_annealing
  
  # 探索と安定化
  entropy_coef: 0.02
  max_grad_norm: 0.5

# ================================================================
# 報酬関数設定（カバレッジ考慮型）★新規追加モード★
# ================================================================
reward:
  core:
    # 報酬モード: coverage_aware（カバレッジ考慮型）
    mode: coverage_aware
    
    # ★★★ 重症系の報酬パラメータ ★★★
    severe_params:
      time_weight: 3.0              # 応答時間の重み（重症は時間重視）
      coverage_weight: 0.0          # カバレッジは考慮しない（重症は最寄り隊を優先）
      under_6min_bonus: 100.0       # 6分以内到達時のボーナス
      over_6min_penalty_per_min: -10.0  # 6分超過時のペナルティ（分あたり）
      target_time: 6                # 目標時間（分）
    
    # ★★★ 軽症系の報酬パラメータ（カバレッジ考慮） ★★★
    mild_params:
      # 時間とカバレッジのバランス
      time_weight: 0.6               # 60%時間重視
      coverage_weight: 0.4           # 40%カバレッジ重視
      
      # 傷病度別の重み
      mild_severity_weight: 0.5      # 軽症の重み
      moderate_severity_weight: 1.5  # 中等症の重み
      
      # 時間制約
      time_limit: 13                 # 目標時間（分）
      time_limit_seconds: 780        # 目標時間（秒）
      
      # ボーナス・ペナルティ
      mild_under_13min_bonus: 10.0           # 軽症13分以内ボーナス
      moderate_under_13min_bonus: 30.0       # 中等症13分以内ボーナス
      over_13min_penalty_per_min: -3.0       # 13分超過ペナルティ（分あたり）
      over_20min_penalty: -50.0              # 20分超過ペナルティ
      
      # ★★★ カバレッジ損失のペナルティスケール ★★★
      coverage_loss_penalty_scale: -100.0
      
      # カバレッジ評価の重み
      coverage_6min_weight: 0.5      # 6分カバレッジの重み
      coverage_13min_weight: 0.5     # 13分カバレッジの重み
      
      # サンプリング設定
      sample_points: 20              # カバレッジ評価のサンプル点数
      sample_radius: 2               # H3リング数
    
    # ★★★ アクションマスク設定（新規追加） ★★★
    action_mask:
      enabled: true
      mild_time_limit_mask: true     # 軽症系の時間制約マスク
      coverage_loss_mask: true       # カバレッジ損失マスク
      coverage_loss_threshold: 0.8   # カバレッジ損失の閾値
    
    # 従来の設定（後方互換性のため残す）
    continuous_params:
      critical:
        target: 6
        max_bonus: 100.0
        penalty_scale: 10.0
        weight: 3.0
      moderate:
        target: 13
        max_bonus: 30.0
        penalty_scale: 3.0
        weight: 1.5
      mild:
        target: 13
        max_bonus: 10.0
        penalty_scale: 0.5
        weight: 0.5
    
    coverage_impact_weight: 0.4
    
    discrete_params:
      penalties:
        over_6min: -10.0
        over_13min: -15.0
        per_minute_over: -2.0
      weights:
        response_time: 2.0
        severity_bonus: 3.0
        coverage_preservation: 0.5
    
    hybrid_params:
      time_penalty_per_minute: -0.3
      mild_under_13min_bonus: 10.0
      moderate_under_13min_bonus: 30.0
      over_13min_penalty: -15.0
      over_20min_penalty: -50.0
      balanced_workload_bonus: 2.0
      coverage_maintenance_bonus: 5.0
      good_coverage_bonus: 10.0
      overloaded_penalty: -5.0
      poor_coverage_penalty: -10.0
    
    simple_params:
      time_penalty_per_minute: -0.5
      critical_under_6min_bonus: 30.0
      mild_under_13min_bonus: 5.0
      moderate_under_13min_bonus: 10.0
      over_13min_penalty: -5.0
      over_20min_penalty: -20.0
      imitation_bonus: 0.0
  
  coverage_params:
    time_threshold_seconds: 360
    drop_penalty_threshold: 0.05
    drop_penalty_weight: -20.0
    evaluation_interval: 100
  
  episode:
    base_penalty_per_minute: -0.3
    failure_penalty_per_incident: -1.0
    achievement_bonuses:
      rate_6min: 20.0
      rate_13min: 10.0
      critical_6min_rate: 100.0
      severe_6min_rate: 150.0
      mild_13min_rate: 30.0
      mild_20min_rate: 20.0
  
  system:
    dispatch_failure: -1.0
    no_available_ambulance: 0.0
    unhandled_call_penalty: -1.0

# 報酬モード設定（後方互換性のため）
reward_mode:
  mode: coverage_aware

# ================================================================
# ハイブリッドモード設定
# ================================================================
hybrid_mode:
  enabled: true
  
  severity_classification:
    severe_conditions: ["重症", "重篤", "死亡"]
    mild_conditions: ["軽症", "中等症"]
  
  time_thresholds:
    good: 13
    warning: 20
  
  reward_weights:
    response_time: 0.7
    coverage: 0.2
    workload_balance: 0.1
  
  penalties:
    per_minute_over: -2.0
    over_warning: -50.0
  
  coverage_evaluation:
    high_risk_weight: 0.85
    normal_weight: 0.15
    min_acceptable: 0.6

# ================================================================
# ネットワーク構造
# ================================================================
network:
  actor:
    hidden_layers: [512, 256, 128]
    activation: relu
    dropout: 0.1
    initialization: xavier_uniform
  critic:
    hidden_layers: [512, 256, 128]
    activation: relu
    dropout: 0.1
    init_scale: 0.001

# ================================================================
# 教師あり学習設定
# ================================================================
teacher:
  enabled: false
  initial_prob: 0.0
  final_prob: 0.0
  decay_episodes: 2000
  strategy: closest
  apply_to: ["軽症", "中等症"]

# ================================================================
# カリキュラム学習設定（オプション）
# ================================================================
curriculum:
  enabled: False
  stages:
    # Stage 1: 応答時間のみ学習（基礎）
    - name: "time_only"
      episodes: [0, 1000]
      reward_mode: "time_only"
      severe_params:
        time_weight: 1.0
        coverage_weight: 0.0
      mild_params:
        time_weight: 1.0
        coverage_weight: 0.0
    
    # Stage 2: カバレッジを導入
    - name: "introduce_coverage"
      episodes: [1000, 3000]
      reward_mode: "coverage_aware"
      severe_params:
        time_weight: 1.0
        coverage_weight: 0.0
      mild_params:
        time_weight: 0.8
        coverage_weight: 0.2
    
    # Stage 3: 最終バランス
    - name: "final_balance"
      episodes: [3000, 5000]
      reward_mode: "coverage_aware"
      severe_params:
        time_weight: 1.0
        coverage_weight: 0.0
      mild_params:
        time_weight: 0.6
        coverage_weight: 0.4

# ================================================================
# 評価設定
# ================================================================
evaluation:
  interval: 100
  n_eval_episodes: 5
  
  metrics:
    - severe_6min_rate
    - severe_mean_rt
    - critical_6min_rate
    - mild_13min_rate
    - mild_20min_rate
    - mild_mean_rt
    - overall_13min_rate
    - overall_mean_rt
    - coverage_score
    - workload_balance
    - vs_closest_improvement
    - dispatch_ratio
  
  compare_baselines:
    - closest
    - severity_based

# ================================================================
# 訓練設定
# ================================================================
training:
  checkpoint_interval: 250
  keep_last_n: 5
  
  early_stopping:
    enabled: true
    metric: severe_6min_rate
    mode: max
    patience: 300
    min_delta: 0.005
  
  logging:
    interval: 10
    wandb: true
    tensorboard: true
    wandb_project: ems_coverage_aware_tokyo23
    hybrid_logs:
      - severe_dispatch_count
      - mild_dispatch_count
      - coverage_history
      - warning_episodes
      - continuous_reward_components
      - coverage_loss        # ★新規追加: カバレッジ損失
      - coverage_6min_rate   # ★新規追加: 6分カバレッジ率
      - coverage_13min_rate  # ★新規追加: 13分カバレッジ率
