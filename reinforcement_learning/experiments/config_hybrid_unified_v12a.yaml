# ================================================================
# config_hybrid_unified_v12a_no_coverage_state.yaml
# 状態空間からカバレッジ情報（L6, L13）を除去
# 
# 【検証目的】
# PPOが状態空間のL6, L13を見て「カバレッジ最小化」に収束している
# 可能性を検証。カバレッジ情報を除去すると何が起きるか？
# 
# 【期待される結果】
# - 直近隊100% → PPOは時間最小化を正しく学習できている
# - 中間的な値 → 別の要因がある
# - 10-18% → カバレッジ情報以外に原因がある
# ================================================================

inherits: ./config.yaml

experiment:
  name: "hybrid_unified_v12a_no_coverage_state"
  description: |
    状態空間からL6, L13を除去
    カバレッジ情報が学習を阻害しているか検証
  seed: 2025
  device: "cuda"

ppo:
  n_episodes: 500
  batch_size: 512
  n_epochs: 4
  clip_epsilon: 0.1
  learning_rate:
    actor: 0.0003
    critic: 0.001
    scheduler: "constant"
  gamma: 0.99
  gae_lambda: 0.95
  entropy_coef: 0.035
  max_grad_norm: 0.5

state_encoding:
  mode: 'compact'
  top_k: 10
  normalization:
    max_travel_time_minutes: 30
    max_station_distance_km: 10
  
  # ★★★ カバレッジ情報を状態空間に含めない ★★★
  coverage_aware_sorting:
    enabled: false   # ★★★ カバレッジソートを無効化 ★★★
    time_weight: 1.0
    coverage_weight: 0.0
    sample_size: 61
    sample_radius: 4
    pre_filter_size: 30
    use_adaptive_sampling: false
    max_candidates_for_advanced: 50
  
  compact_coverage:
    enabled: false   # ★★★ カバレッジ特徴量を無効化 ★★★
    sample_radius: 4
    sample_size: 61

hybrid_mode:
  enabled: true
  severity_classification:
    severe_conditions: ["重症", "重篤", "死亡"]
    mild_conditions: ["軽症", "中等症"]

reward:
  system:
    dispatch_failure: -1.0
    no_available_ambulance: 0.0
  unified:
    score_based_mode: false
    # 時間報酬のみ（カバレッジペナルティなし）
    mild_max_bonus: 10.0
    mild_penalty_scale: 1.0
    coverage_penalty_scale: 0.0   # ★★★ カバレッジペナルティを0に ★★★
    coverage_w6: 0.5
    coverage_w13: 0.5
    time_weight: 1.0              # ★★★ 時間のみ ★★★
    coverage_weight: 0.0          # ★★★ カバレッジ無視 ★★★
    critical_max_bonus: 50.0
    critical_lambda: 0.115
    critical_penalty_scale: 5.0
    critical_penalty_power: 1.5
  core:
    mild_params:
      sample_points: 61
      sample_radius: 4
      coverage_6min_weight: 0.5
      coverage_13min_weight: 0.5

network:
  actor:
    hidden_layers: [128, 64]
    activation: "relu"
    dropout: 0.2
  critic:
    hidden_layers: [128, 64]
    activation: "relu"
    dropout: 0.1

training:
  checkpoint_interval: 500
  keep_last_n: 7
  early_stopping:
    enabled: true
    patience: 500
    min_delta: 0.001
  logging:
    interval: 50
    tensorboard: false
    wandb: true
    wandb_project: "ems_ppo_hybrid"

evaluation:
  interval: 500
  n_eval_episodes: 10
  compare_baselines: ["closest"]
  metrics:
    - "critical_6min_rate"
    - "achieved_13min_rate"
    - "mean_response_time"
    - "non_closest_selection_rate"

data:
  data_paths:
    grid_mapping: "data/tokyo/processed/grid_mapping_res9.json"
    travel_time_matrix: "data/tokyo/calibration2/linear_calibrated_response.npy"
  episode_duration_hours: 24
  exclude_daytime_ambulances: true
  area_restriction:
    enabled: false
  train_periods:
    - start_date: "20230401"
      end_date: "20230430"
  eval_periods:
    - start_date: "20230501"
      end_date: "20230507"

severity:
  categories:
    critical:
      conditions: ["重症", "重篤", "死亡"]
      reward_weight: 1.0
    mild:
      conditions: ["軽症", "中等症"]
      reward_weight: 1.0
